import json
import tempfile
import os
import csv

from aiogram.types import FSInputFile
from aiogram import Router, F
from aiogram.types import Message
from aiogram.filters import CommandStart
from aiogram.fsm.context import FSMContext
from typing import Any

from bot.lexicon import LEXICON, LEXICON_COMMANDS
import bot.menu_kb as kb
from bot.menu_kb import sites_keyboard, employment_types_keyboard

from common.database import initialize_databases, Internships, EmploymentTypes

from common.logger import get_logger


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–æ—É—Ç–µ—Ä–∞
router: Router = Router()

logger = get_logger(__name__)

# –•—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
user_history: dict[int, list] = dict()
user_state: dict[int, dict[str, Any]] = dict()
query: dict[int, dict[str, str | int | list]] = dict()


async def add_to_query(state: FSMContext, **kwargs):
    data = await state.get_data()
    current_filters = data.get("filters", {})

    for key, value in kwargs.items():
        if not isinstance(value, list):
            value = value.split(",")

        current = current_filters.get(key, [])
        current_filters[key] = list(set(current + value))

    await state.update_data(filters=current_filters)


async def remove_from_query(state: FSMContext, **kwargs):
    data = await state.get_data()
    current_filters = data.get("filters", {})

    for key, values in kwargs.items():
        if not isinstance(values, list):
            values = values.split(",")

        if key in current_filters:
            current_filters[key] = [
                v for v in current_filters[key] if v not in values
            ]
            if not current_filters[key]:
                del current_filters[key]

    await state.update_data(filters=current_filters)


# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ–Ω—é –≤ –∏—Å—Ç–æ—Ä–∏—é –ø–µ—Ä–µ—Ö–æ–¥–æ–≤
def add_to_history(user_id: int, menu: Any):
    """–î–æ–±–∞–≤–ª—è–µ–º –º–µ–Ω—é –≤ –∏—Å—Ç–æ—Ä–∏—é –ø–µ—Ä–µ—Ö–æ–¥–æ–≤"""
    if user_id not in user_history:
        user_history[user_id] = []
    user_history[user_id].append(menu)


# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –º–µ–Ω—é
def get_previous_menu(user_id: int) -> Any:
    """–ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –º–µ–Ω—é"""
    if user_id in user_history and len(user_history[user_id]) > 1:
        user_history[user_id].pop()  # –£–¥–∞–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ –º–µ–Ω—é
        return user_history[user_id][-1]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–µ
    return None


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–∫–∏ "–ù–∞–∑–∞–¥"
@router.message(F.text == LEXICON_COMMANDS["back"])
async def back_handler(message: Message, state: FSMContext):
    user_id = message.from_user.id
    previous_menu = get_previous_menu(user_id)

    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    data = await state.get_data()
    filters = data.get("filters", {})
    selected_sites = filters.get("source_name", [])

    if previous_menu:
        if previous_menu == "start":
            await message.answer(
                text=LEXICON["main_menu"],
                reply_markup=kb.StartMenu
            )

        elif previous_menu == "sites_menu":
            await message.answer(
                text=LEXICON["select_site"],
                reply_markup=sites_keyboard(selected_sites)
            )

        elif previous_menu == "filters_menu":
            await message.answer(
                text=LEXICON["select_filters"],
                reply_markup=kb.FiltersMenu
            )
    else:
        await message.answer(
            text=LEXICON["main_menu"], reply_markup=kb.StartMenu
        )
        user_history[user_id] = [kb.StartMenu]


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /start
@router.message(CommandStart())
async def cmd_start(message: Message):
    user_id = message.from_user.id
    add_to_history(user_id, "start")
    await message.answer(LEXICON["/start"], reply_markup=kb.StartMenu)


@router.message(F.text == LEXICON_COMMANDS["export_file"])
async def export_file(message: Message):
    await message.answer(
        text=LEXICON["choose_file_type"],
        reply_markup=kb.ExportFileMenu
    )


def format_txt(data: list) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç"""
    result = []
    for item in data:
        txt_entry = [
            f"ID: {item['id']}",
            f"–î–æ–ª–∂–Ω–æ—Å—Ç—å: {item['profession']}",
            f"–ö–æ–º–ø–∞–Ω–∏—è: {item['company_name']}",
            f"–ó–∞—Ä–ø–ª–∞—Ç–∞: {item['salary_from']}-{item['salary_to']}",
            f"–ò—Å—Ç–æ—á–Ω–∏–∫: {item['source_name']}",
            f"–¢–∏–ø –∑–∞–Ω—è—Ç–æ—Å—Ç–∏: {item['employment_types']}",
            f"–°—Å—ã–ª–∫–∞: {item['link']}",
            f"–û–ø–∏—Å–∞–Ω–∏–µ: {item['description']}",
            "-" * 40
        ]
        result.append("\n".join(txt_entry))
    return "\n\n".join(result)


def write_json(data: list, file_path: str):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ JSON —Ñ–∞–π–ª"""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)


def write_csv(data: list, file_path: str):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ CSV —Ñ–∞–π–ª"""
    if not data:
        return

    fieldnames = data[0].keys()
    with open(file_path, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(data)


def write_txt(data: list, file_path: str):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ TXT —Ñ–∞–π–ª"""
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(format_txt(data))


@router.message(F.text.in_({"json", "csv", "txt"}))
async def process_export_file(message: Message, state: FSMContext):
    await message.answer(text=LEXICON["processing"])

    file_type = message.text
    file_ext = f".{file_type}"
    file_name = f"internships{file_ext}"

    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        data = await state.get_data()
        filters = data.get("filters", {})

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
        tables = await initialize_databases()
        internships_table: Internships = tables[1]
        result = await internships_table.select_internship_data(**filters)

        if not result:
            await message.answer("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            await state.clear()
            return

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
        headers = [
            'id', 'title', 'profession', 'company_name', 'salary_from',
            'salary_to', 'source_name', 'link',
            'description', 'created_at', 'employment_types'
        ]

        json_data = []
        for row in result:
            item = {
                header: str(value) if value is not None else ''
                for header, value in zip(headers, row)
            }
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø–æ–ª–µ–π
            for numeric_field in ['id', 'salary_from', 'salary_to']:
                if item[numeric_field].isdigit():
                    item[numeric_field] = int(item[numeric_field])

            json_data.append(item)

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω—É–∂–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
        with tempfile.NamedTemporaryFile(
            mode='w',
            suffix=file_ext,
            delete=False,
            encoding='utf-8',
            newline='' if file_type == 'csv' else None
        ) as tmpfile:
            tmpfile_path = tmpfile.name

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞
        if file_type == "json":
            write_json(json_data, tmpfile_path)
        elif file_type == "csv":
            write_csv(json_data, tmpfile_path)
        elif file_type == "txt":
            write_txt(json_data, tmpfile_path)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        document = FSInputFile(
            path=tmpfile_path,
            filename=file_name
        )

        await message.answer_document(
            document=document,
            caption=f'üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ —Å—Ç–∞–∂–∏—Ä–æ–≤–æ–∫ ({file_type.upper()})',
            reply_markup=kb.StartMenu
        )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ —Ñ–∞–π–ª–∞: {e}")
        await message.answer(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        if 'tmpfile_path' in locals() and os.path.exists(tmpfile_path):
            try:
                os.remove(tmpfile_path)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        await state.clear()


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–∫–∏ "–î–∞–ª–µ–µ"
@router.message(F.text == LEXICON_COMMANDS["next"])
async def process_sites(message: Message):
    user_id = message.from_user.id

    add_to_history(user_id, "filters_menu")
    await message.answer(
        text=LEXICON["select_filters"],
        reply_markup=kb.FiltersMenu
    )
